"""UCCA For TAC

Usage:
  enhance_tac2.py <tupa_module_path>  [--input=<input-file>] [--output=<output-file>]
  enhance_tac2.py (-h | --help)

Options:
  -h --help     Show this screen.
"""
import sys
import ijson
import jsonlines
from semstr.convert import to_conllu
from conllu import parse as conllu_parse

from docopt import docopt

from tacred_enrichment.internal.sanitize_tacred import SanitizeTacred
from tacred_enrichment.internal.map_tokenization import MapTokenization
from tacred_enrichment.internal.pipe_error_work_around import revert_to_default_behaviour_on_sigpipe
from tacred_enrichment.internal.tupa_parser import TupaParser



def enhance_tac2(input_stream, output_stream, model_prefix):

#   json_read = ijson.items(input_stream, 'item')
    json_read = jsonlines.Reader(input_stream)


    with jsonlines.Writer(output_stream) as json_write:

        parser = TupaParser(model_prefix)


        for item in json_read:
            sentence = ' '.join(SanitizeTacred.sanitize_tokens(item['token']))
            parsed_sentence = parser.parse_sentence(sentence)
            if parsed_sentence is None:
                print('failed to perform UCCA parse')
                continue

            sanitized_tac_tokens = SanitizeTacred.sanitize_tokens(item['token'])
            ucca_tokens = [ucca_terminal.text for ucca_terminal in parsed_sentence.terminals]
            tac_to_ucca = MapTokenization.map_a_to_b(sanitized_tac_tokens, ucca_tokens)

            #ensure tac_to_ucca is 'surjective' over 'ucca_tokens':
            tac_to_ucca_coverage = {ucca_token: True for ucca_tokens in tac_to_ucca.values() for ucca_token in ucca_tokens}
            if (len(tac_to_ucca_coverage) != len(ucca_tokens)) \
                    or (0 not in tac_to_ucca_coverage) \
                    or ((len(tac_to_ucca_coverage)-1) not in tac_to_ucca_coverage):
                print('failed to align all UCCA and TACRED tokens for UCCA head/dep extraction')
                continue

            #ensure tac_to_ucca range is defined over 'sanitized_tac_tokens'
            tac_to_ucca_defined = {tac_token: True for tac_token in tac_to_ucca.keys()}
            if (len(tac_to_ucca_defined) != len(sanitized_tac_tokens)) \
                    or (0 not in tac_to_ucca_defined) \
                    or ((len(tac_to_ucca_defined)-1) not in tac_to_ucca_defined):
                print('failed to align all UCCA and TACRED tokens for UCCA head/dep extraction')
                continue

            item['tac_to_ucca'] = tac_to_ucca
            item['ucca_tokens'] = ucca_tokens

            lines_representation = to_conllu(parsed_sentence.native)
            conllu = conllu_parse('\n'.join(lines_representation))
            item['ucca_heads'] = [token_info['head'] for i, token_info in enumerate(conllu[0])]
            item['ucca_deps'] = [token_info['deps'] for i, token_info in enumerate(conllu[0])]

            item['ucca_tags'] = [ucca_terminal.tag for ucca_terminal in parsed_sentence.terminals]
            item['ucca_poss'] = [ucca_terminal.pos for ucca_terminal in parsed_sentence.terminals]
            item['ucca_ents'] = [ucca_terminal.ent for ucca_terminal in parsed_sentence.terminals]
            item['ucca_parse'] = parsed_sentence.serialize()

            json_write.write(item)


if __name__ == "__main__":
    args = docopt(__doc__)

    input_stream = open(args['--input'], encoding='utf-8') if args['--input'] is not None else sys.stdin
    output_stream = open(args['--output'], 'w', encoding='utf-8', newline='', buffering=1) if args['--output'] is not None else sys.stdout
    tupa_module_path = args.get('<tupa_module_path>', None)

    # https://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-python
    revert_to_default_behaviour_on_sigpipe()

    enhance_tac2(input_stream, output_stream, tupa_module_path)

